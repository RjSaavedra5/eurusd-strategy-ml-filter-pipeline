{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3f7b83",
   "metadata": {},
   "source": [
    "Este notebook construye la base de datos operativa del proyecto a partir de tick data de Dukascopy (2021–2025). Primero descarga y consolida los ticks, luego limita el universo al horario líquido (07:00–22:00 UTC) y transforma los datos a velas OHLC de 5 segundos. El resultado se guarda en formato parquet para facilitar lecturas rápidas en las etapas posteriores. Además, incluye una auditoría básica de calidad que revisa continuidad temporal, duplicados, coherencia OHLC y comportamiento del spread, generando un reporte de incidencias cuando se detectan anomalías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b759be5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EURUSD 2025: 100%|██████████| 8760/8760 [34:02<00:00,  4.29it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ data/EURUSD/EURUSD_5s_2025-01.parquet | velas: 192390\n",
      "✔ data/EURUSD/EURUSD_5s_2025-02.parquet | velas: 194288\n",
      "✔ data/EURUSD/EURUSD_5s_2025-03.parquet | velas: 216961\n",
      "✔ data/EURUSD/EURUSD_5s_2025-04.parquet | velas: 207462\n",
      "✔ data/EURUSD/EURUSD_5s_2025-05.parquet | velas: 194502\n",
      "✔ data/EURUSD/EURUSD_5s_2025-06.parquet | velas: 189713\n",
      "✔ data/EURUSD/EURUSD_5s_2025-07.parquet | velas: 179480\n",
      "✔ data/EURUSD/EURUSD_5s_2025-08.parquet | velas: 191991\n",
      "✔ data/EURUSD/EURUSD_5s_2025-09.parquet | velas: 190988\n",
      "✔ data/EURUSD/EURUSD_5s_2025-10.parquet | velas: 171912\n",
      "✔ data/EURUSD/EURUSD_5s_2025-11.parquet | velas: 184106\n",
      "Descarga 2025 completada.\n"
     ]
    }
   ],
   "source": [
    "# Descarga EURUSD ticks de Dukascopy para 2025,\n",
    "# filtra UTC 07:00–22:00, resamplea a velas de 5s y guarda Parquet por mes.\n",
    "\n",
    "import datetime as dt\n",
    "import lzma\n",
    "import struct\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# CONFIGURACIÓN GENERAL\n",
    "\n",
    "BASE_URL = \"https://datafeed.dukascopy.com/datafeed\"\n",
    "SYMBOL = \"EURUSD\"\n",
    "PRICE_SCALE = 100000          # EURUSD\n",
    "MAX_WORKERS = 12              # threads\n",
    "OUT_DIR = Path(\"./data\") / SYMBOL\n",
    "\n",
    "# Ventana operativa UTC\n",
    "UTC_START = dt.time(7, 0, 0)\n",
    "UTC_END = dt.time(22, 0, 0)\n",
    "\n",
    "# BI5 record format\n",
    "REC = struct.Struct(\">iii ff\")\n",
    "REC_SIZE = REC.size\n",
    "\n",
    "\n",
    "\n",
    "# UTILIDADES\n",
    "\n",
    "def dukascopy_hour_url(symbol: str, hour_start: dt.datetime) -> str:\n",
    "    return (\n",
    "        f\"{BASE_URL}/{symbol}/\"\n",
    "        f\"{hour_start.year:04d}/{hour_start.month:02d}/{hour_start.day:02d}/\"\n",
    "        f\"{hour_start.hour:02d}h_ticks.bi5\"\n",
    "    )\n",
    "\n",
    "\n",
    "def download_bytes(url: str, timeout: int = 20, retries: int = 2) -> bytes | None:\n",
    "    for _ in range(retries + 1):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=timeout)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                return r.content\n",
    "            return None\n",
    "        except requests.RequestException:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def decode_bi5(bi5: bytes, hour_start: dt.datetime) -> pl.DataFrame:\n",
    "    raw = lzma.decompress(bi5)\n",
    "    raw = raw[: (len(raw) // REC_SIZE) * REC_SIZE]\n",
    "\n",
    "    if not raw:\n",
    "        return pl.DataFrame(schema={\n",
    "            \"ts\": pl.Datetime(\"ms\"),\n",
    "            \"bid\": pl.Float64,\n",
    "            \"ask\": pl.Float64,\n",
    "            \"bid_vol\": pl.Float32,\n",
    "            \"ask_vol\": pl.Float32,\n",
    "        })\n",
    "\n",
    "    ts, bid, ask, bidv, askv = [], [], [], [], []\n",
    "\n",
    "    for off in range(0, len(raw), REC_SIZE):\n",
    "        time_ms, ask_i, bid_i, ask_v, bid_v = REC.unpack_from(raw, off)\n",
    "        ts.append(hour_start + dt.timedelta(milliseconds=int(time_ms)))\n",
    "        bid.append(bid_i / PRICE_SCALE)\n",
    "        ask.append(ask_i / PRICE_SCALE)\n",
    "        bidv.append(float(bid_v))\n",
    "        askv.append(float(ask_v))\n",
    "\n",
    "    return pl.DataFrame({\n",
    "        \"ts\": ts,\n",
    "        \"bid\": bid,\n",
    "        \"ask\": ask,\n",
    "        \"bid_vol\": bidv,\n",
    "        \"ask_vol\": askv,\n",
    "    }).with_columns(pl.col(\"ts\").cast(pl.Datetime(\"ms\")))\n",
    "\n",
    "\n",
    "def filter_utc_window(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    if df.height == 0:\n",
    "        return df\n",
    "\n",
    "    t = pl.col(\"ts\").dt.time()\n",
    "    return df.filter(\n",
    "        (t >= pl.time(UTC_START.hour, UTC_START.minute, 0)) &\n",
    "        (t <  pl.time(UTC_END.hour, UTC_END.minute, 0))\n",
    "    )\n",
    "\n",
    "\n",
    "def resample_5s(df_ticks: pl.DataFrame) -> pl.DataFrame:\n",
    "    if df_ticks.height == 0:\n",
    "        return pl.DataFrame(schema={\n",
    "            \"ts\": pl.Datetime(\"ms\"),\n",
    "            \"open\": pl.Float64,\n",
    "            \"high\": pl.Float64,\n",
    "            \"low\": pl.Float64,\n",
    "            \"close\": pl.Float64,\n",
    "            \"ticks\": pl.UInt32,\n",
    "            \"bid_last\": pl.Float64,\n",
    "            \"ask_last\": pl.Float64,\n",
    "            \"bid_vol_sum\": pl.Float64,\n",
    "            \"ask_vol_sum\": pl.Float64,\n",
    "        })\n",
    "\n",
    "    df = (\n",
    "        df_ticks.sort(\"ts\")\n",
    "        .with_columns(mid=((pl.col(\"bid\") + pl.col(\"ask\")) / 2))\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        df.group_by_dynamic(\n",
    "            index_column=\"ts\",\n",
    "            every=\"5s\",\n",
    "            period=\"5s\",\n",
    "            closed=\"left\",\n",
    "            label=\"left\",\n",
    "        )\n",
    "        .agg(\n",
    "            pl.col(\"mid\").first().alias(\"open\"),\n",
    "            pl.col(\"mid\").max().alias(\"high\"),\n",
    "            pl.col(\"mid\").min().alias(\"low\"),\n",
    "            pl.col(\"mid\").last().alias(\"close\"),\n",
    "            pl.len().cast(pl.UInt32).alias(\"ticks\"),\n",
    "            pl.col(\"bid\").last().alias(\"bid_last\"),\n",
    "            pl.col(\"ask\").last().alias(\"ask_last\"),\n",
    "            pl.col(\"bid_vol\").sum().alias(\"bid_vol_sum\"),\n",
    "            pl.col(\"ask_vol\").sum().alias(\"ask_vol_sum\"),\n",
    "        )\n",
    "        .drop_nulls([\"open\", \"high\", \"low\", \"close\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def iter_hours(start: dt.datetime, end: dt.datetime):\n",
    "    cur = start\n",
    "    while cur <= end:\n",
    "        yield cur\n",
    "        cur += dt.timedelta(hours=1)\n",
    "\n",
    "\n",
    "\n",
    "# PIPELINE PRINCIPAL\n",
    "\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    year = 2025\n",
    "    start = dt.datetime(year, 1, 1, 0, 0, 0)\n",
    "    end = dt.datetime(year, 12, 31, 23, 0, 0)\n",
    "    hours = list(iter_hours(start, end))\n",
    "\n",
    "    def process_hour(hour_start: dt.datetime) -> tuple[str, pl.DataFrame]:\n",
    "        url = dukascopy_hour_url(SYMBOL, hour_start)\n",
    "        bi5 = download_bytes(url)\n",
    "        if not bi5:\n",
    "            return \"\", pl.DataFrame()\n",
    "\n",
    "        ticks = decode_bi5(bi5, hour_start)\n",
    "        ticks = filter_utc_window(ticks)\n",
    "        candles = resample_5s(ticks)\n",
    "\n",
    "        month_key = f\"{hour_start.year:04d}-{hour_start.month:02d}\"\n",
    "        return month_key, candles\n",
    "\n",
    "    buffers: dict[str, list[pl.DataFrame]] = {}\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "        futures = [ex.submit(process_hour, h) for h in hours]\n",
    "\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), desc=\"EURUSD 2025\"):\n",
    "            month_key, dfh = f.result()\n",
    "            if dfh.height:\n",
    "                buffers.setdefault(month_key, []).append(dfh)\n",
    "\n",
    "    for month, parts in buffers.items():\n",
    "        df_month = (\n",
    "            pl.concat(parts, how=\"vertical\")\n",
    "            .sort(\"ts\")\n",
    "            .unique(subset=[\"ts\"], keep=\"last\")\n",
    "        )\n",
    "\n",
    "        out_path = OUT_DIR / f\"{SYMBOL}_5s_{month}.parquet\"\n",
    "        df_month.write_parquet(out_path)\n",
    "        print(f\"✔ {out_path} | velas: {df_month.height}\")\n",
    "\n",
    "    print(\"Descarga 2025 completada.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # pip install polars requests tqdm\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d4305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESUMEN POR MES ===\n",
      "shape: (11, 15)\n",
      "┌───────────────┬────────┬────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ file          ┆ rows   ┆ dup_ts ┆ gaps_gt_5s ┆ … ┆ ticks_min ┆ ticks_med ┆ ticks_p95 ┆ ticks_max │\n",
      "│ ---           ┆ ---    ┆ ---    ┆ ---        ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ str           ┆ i64    ┆ i64    ┆ i64        ┆   ┆ i64       ┆ f64       ┆ f64       ┆ i64       │\n",
      "╞═══════════════╪════════╪════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ EURUSD_5s_202 ┆ 192390 ┆ 0      ┆ 15091      ┆ … ┆ 1         ┆ 6.0       ┆ 20.0      ┆ 73        │\n",
      "│ 5-01.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "│ EURUSD_5s_202 ┆ 194288 ┆ 0      ┆ 11800      ┆ … ┆ 1         ┆ 7.0       ┆ 22.0      ┆ 71        │\n",
      "│ 5-02.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "│ EURUSD_5s_202 ┆ 216961 ┆ 0      ┆ 10491      ┆ … ┆ 1         ┆ 10.0      ┆ 32.0      ┆ 76        │\n",
      "│ 5-03.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "│ EURUSD_5s_202 ┆ 207462 ┆ 0      ┆ 15991      ┆ … ┆ 1         ┆ 7.0       ┆ 20.0      ┆ 69        │\n",
      "│ 5-04.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "│ EURUSD_5s_202 ┆ 194502 ┆ 0      ┆ 18252      ┆ … ┆ 1         ┆ 6.0       ┆ 18.0      ┆ 73        │\n",
      "│ 5-05.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "│ …             ┆ …      ┆ …      ┆ …          ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
      "│ EURUSD_5s_202 ┆ 179480 ┆ 0      ┆ 27346      ┆ … ┆ 1         ┆ 4.0       ┆ 15.0      ┆ 73        │\n",
      "│ 5-07.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "│ EURUSD_5s_202 ┆ 191991 ┆ 0      ┆ 25679      ┆ … ┆ 1         ┆ 4.0       ┆ 16.0      ┆ 76        │\n",
      "│ 5-08.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "│ EURUSD_5s_202 ┆ 190988 ┆ 0      ┆ 26544      ┆ … ┆ 1         ┆ 4.0       ┆ 15.0      ┆ 76        │\n",
      "│ 5-09.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "│ EURUSD_5s_202 ┆ 171912 ┆ 0      ┆ 25571      ┆ … ┆ 1         ┆ 4.0       ┆ 14.0      ┆ 78        │\n",
      "│ 5-10.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "│ EURUSD_5s_202 ┆ 184106 ┆ 0      ┆ 26398      ┆ … ┆ 1         ┆ 4.0       ┆ 14.0      ┆ 68        │\n",
      "│ 5-11.parquet  ┆        ┆        ┆            ┆   ┆           ┆           ┆           ┆           │\n",
      "└───────────────┴────────┴────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "\n",
      "=== CHEQUEOS GLOBALES ===\n",
      "Meses con duplicados: []\n",
      "Meses con OHLC inválido: []\n",
      "Meses con spread negativo: []\n",
      "\n",
      "=== SPREAD GLOBAL ===\n",
      "shape: (1, 3)\n",
      "┌────────────┬──────────┬──────────┐\n",
      "│ avg_median ┆ avg_p95  ┆ max_seen │\n",
      "│ ---        ┆ ---      ┆ ---      │\n",
      "│ f64        ┆ f64      ┆ f64      │\n",
      "╞════════════╪══════════╪══════════╡\n",
      "│ 0.445455   ┆ 0.790909 ┆ 31.4     │\n",
      "└────────────┴──────────┴──────────┘\n",
      "\n",
      "=== ACTIVIDAD (ticks/vela) ===\n",
      "shape: (1, 3)\n",
      "┌───────────────┬───────────────┬────────────────┐\n",
      "│ avg_ticks_med ┆ avg_ticks_p95 ┆ max_ticks_seen │\n",
      "│ ---           ┆ ---           ┆ ---            │\n",
      "│ f64           ┆ f64           ┆ i64            │\n",
      "╞═══════════════╪═══════════════╪════════════════╡\n",
      "│ 5.454545      ┆ 18.363636     ┆ 78             │\n",
      "└───────────────┴───────────────┴────────────────┘\n",
      "\n",
      "✅ Quality check finalizado.\n"
     ]
    }
   ],
   "source": [
    "# Control de calidad para velas 5s EURUSD (UTC fijo)\n",
    "# Reviso gaps, duplicados, OHLC, spread y actividad\n",
    "\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "DATA_DIR = Path(\"./data/EURUSD\")\n",
    "PIP = 0.0001  # EURUSD\n",
    "\n",
    "\n",
    "def check_month(file: Path) -> dict:\n",
    "    df = pl.read_parquet(file).sort(\"ts\")\n",
    "\n",
    "    # Spread\n",
    "    df = df.with_columns(\n",
    "        spread=(pl.col(\"ask_last\") - pl.col(\"bid_last\")),\n",
    "        spread_pips=(pl.col(\"ask_last\") - pl.col(\"bid_last\")) / PIP,\n",
    "    )\n",
    "\n",
    "    # Checks\n",
    "    out = {}\n",
    "    out[\"file\"] = file.name\n",
    "    out[\"rows\"] = df.height\n",
    "\n",
    "    # 1) Duplicados\n",
    "    out[\"dup_ts\"] = (df.height - df.select(pl.col(\"ts\").n_unique()).item())\n",
    "\n",
    "    # 2) Gaps\n",
    "    gaps = df.select(\n",
    "        pl.col(\"ts\").diff().dt.total_seconds().fill_null(5).alias(\"dt_s\")\n",
    "    )\n",
    "    out[\"gaps_gt_5s\"] = gaps.select((pl.col(\"dt_s\") > 5).sum()).item()\n",
    "    out[\"max_gap_s\"] = gaps.select(pl.col(\"dt_s\").max()).item()\n",
    "\n",
    "    # 3) OHLC inválido\n",
    "    out[\"invalid_ohlc\"] = df.filter(\n",
    "        (pl.col(\"high\") < pl.col(\"low\")) |\n",
    "        (pl.col(\"open\") < pl.col(\"low\")) | (pl.col(\"open\") > pl.col(\"high\")) |\n",
    "        (pl.col(\"close\") < pl.col(\"low\")) | (pl.col(\"close\") > pl.col(\"high\"))\n",
    "    ).height\n",
    "\n",
    "    # 4) Spread\n",
    "    out[\"spread_neg\"] = df.filter(pl.col(\"spread\") < 0).height\n",
    "    out[\"spread_zero\"] = df.filter(pl.col(\"spread\") == 0).height\n",
    "\n",
    "    spread_stats = df.select([\n",
    "        pl.col(\"spread_pips\").median().alias(\"median_pips\"),\n",
    "        pl.col(\"spread_pips\").quantile(0.95).alias(\"p95_pips\"),\n",
    "        pl.col(\"spread_pips\").max().alias(\"max_pips\"),\n",
    "    ]).row(0)\n",
    "\n",
    "    out[\"spread_median\"] = spread_stats[0]\n",
    "    out[\"spread_p95\"] = spread_stats[1]\n",
    "    out[\"spread_max\"] = spread_stats[2]\n",
    "\n",
    "    # 5) Actividad\n",
    "    ticks_stats = df.select([\n",
    "        pl.col(\"ticks\").min().alias(\"ticks_min\"),\n",
    "        pl.col(\"ticks\").median().alias(\"ticks_med\"),\n",
    "        pl.col(\"ticks\").quantile(0.95).alias(\"ticks_p95\"),\n",
    "        pl.col(\"ticks\").max().alias(\"ticks_max\"),\n",
    "    ]).row(0)\n",
    "\n",
    "    out[\"ticks_min\"] = ticks_stats[0]\n",
    "    out[\"ticks_med\"] = ticks_stats[1]\n",
    "    out[\"ticks_p95\"] = ticks_stats[2]\n",
    "    out[\"ticks_max\"] = ticks_stats[3]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def main():\n",
    "    files = sorted(DATA_DIR.glob(\"EURUSD_5s_2025-*.parquet\"))\n",
    "\n",
    "    if not files:\n",
    "        print(\"❌ No se encontraron archivos parquet.\")\n",
    "        return\n",
    "\n",
    "    results = []\n",
    "    for f in files:\n",
    "        res = check_month(f)\n",
    "        results.append(res)\n",
    "\n",
    "    df_res = pl.DataFrame(results)\n",
    "\n",
    "    print(\"\\n=== RESUMEN POR MES ===\")\n",
    "    print(df_res)\n",
    "\n",
    "    print(\"\\n=== CHEQUEOS GLOBALES ===\")\n",
    "    print(\"Meses con duplicados:\",\n",
    "          df_res.filter(pl.col(\"dup_ts\") > 0).select(\"file\").to_series().to_list())\n",
    "\n",
    "    print(\"Meses con OHLC inválido:\",\n",
    "          df_res.filter(pl.col(\"invalid_ohlc\") > 0).select(\"file\").to_series().to_list())\n",
    "\n",
    "    print(\"Meses con spread negativo:\",\n",
    "          df_res.filter(pl.col(\"spread_neg\") > 0).select(\"file\").to_series().to_list())\n",
    "\n",
    "    print(\"\\n=== SPREAD GLOBAL ===\")\n",
    "    print(\n",
    "        df_res.select([\n",
    "            pl.col(\"spread_median\").mean().alias(\"avg_median\"),\n",
    "            pl.col(\"spread_p95\").mean().alias(\"avg_p95\"),\n",
    "            pl.col(\"spread_max\").max().alias(\"max_seen\"),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== ACTIVIDAD (ticks/vela) ===\")\n",
    "    print(\n",
    "        df_res.select([\n",
    "            pl.col(\"ticks_med\").mean().alias(\"avg_ticks_med\"),\n",
    "            pl.col(\"ticks_p95\").mean().alias(\"avg_ticks_p95\"),\n",
    "            pl.col(\"ticks_max\").max().alias(\"max_ticks_seen\"),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    print(\"\\n✅ Quality check finalizado.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a61447f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP 50 SPREAD BARS (2025) ===\n",
      "shape: (50, 6)\n",
      "┌─────────────────────┬──────────┬──────────┬───────┬─────────────┬───────────────────────────┐\n",
      "│ ts                  ┆ bid_last ┆ ask_last ┆ ticks ┆ spread_pips ┆ file                      │\n",
      "│ ---                 ┆ ---      ┆ ---      ┆ ---   ┆ ---         ┆ ---                       │\n",
      "│ datetime[ms]        ┆ f64      ┆ f64      ┆ u32   ┆ f64         ┆ str                       │\n",
      "╞═════════════════════╪══════════╪══════════╪═══════╪═════════════╪═══════════════════════════╡\n",
      "│ 2025-02-20 21:04:00 ┆ 1.084    ┆ 1.08714  ┆ 1     ┆ 31.4        ┆ EURUSD_5s_2025-02.parquet │\n",
      "│ 2025-11-25 07:47:50 ┆ 1.17663  ┆ 1.179    ┆ 1     ┆ 23.7        ┆ EURUSD_5s_2025-11.parquet │\n",
      "│ 2025-11-25 07:43:35 ┆ 1.17701  ┆ 1.1793   ┆ 2     ┆ 22.9        ┆ EURUSD_5s_2025-11.parquet │\n",
      "│ 2025-11-25 07:43:40 ┆ 1.17701  ┆ 1.17929  ┆ 1     ┆ 22.8        ┆ EURUSD_5s_2025-11.parquet │\n",
      "│ 2025-11-25 07:43:50 ┆ 1.177    ┆ 1.17928  ┆ 2     ┆ 22.8        ┆ EURUSD_5s_2025-11.parquet │\n",
      "│ …                   ┆ …        ┆ …        ┆ …     ┆ …           ┆ …                         │\n",
      "│ 2025-06-20 21:04:10 ┆ 1.16236  ┆ 1.16367  ┆ 1     ┆ 13.1        ┆ EURUSD_5s_2025-06.parquet │\n",
      "│ 2025-06-20 21:04:25 ┆ 1.16239  ┆ 1.16367  ┆ 1     ┆ 12.8        ┆ EURUSD_5s_2025-06.parquet │\n",
      "│ 2025-06-04 20:59:00 ┆ 1.17719  ┆ 1.17844  ┆ 1     ┆ 12.5        ┆ EURUSD_5s_2025-06.parquet │\n",
      "│ 2025-08-14 21:05:10 ┆ 1.17279  ┆ 1.17403  ┆ 1     ┆ 12.4        ┆ EURUSD_5s_2025-08.parquet │\n",
      "│ 2025-05-26 21:14:25 ┆ 1.16997  ┆ 1.17118  ┆ 2     ┆ 12.1        ┆ EURUSD_5s_2025-05.parquet │\n",
      "└─────────────────────┴──────────┴──────────┴───────┴─────────────┴───────────────────────────┘\n",
      "\n",
      "=== PEOR CASO ===\n",
      "shape: (1, 6)\n",
      "┌─────────────────────┬──────────┬──────────┬───────┬─────────────┬───────────────────────────┐\n",
      "│ ts                  ┆ bid_last ┆ ask_last ┆ ticks ┆ spread_pips ┆ file                      │\n",
      "│ ---                 ┆ ---      ┆ ---      ┆ ---   ┆ ---         ┆ ---                       │\n",
      "│ datetime[ms]        ┆ f64      ┆ f64      ┆ u32   ┆ f64         ┆ str                       │\n",
      "╞═════════════════════╪══════════╪══════════╪═══════╪═════════════╪═══════════════════════════╡\n",
      "│ 2025-02-20 21:04:00 ┆ 1.084    ┆ 1.08714  ┆ 1     ┆ 31.4        ┆ EURUSD_5s_2025-02.parquet │\n",
      "└─────────────────────┴──────────┴──────────┴───────┴─────────────┴───────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "DATA_DIR = Path(\"./data/EURUSD\")\n",
    "PIP = 0.0001\n",
    "\n",
    "files = sorted(DATA_DIR.glob(\"EURUSD_5s_2025-*.parquet\"))\n",
    "\n",
    "rows = []\n",
    "for f in files:\n",
    "    df = pl.read_parquet(f).with_columns(\n",
    "        spread_pips=(pl.col(\"ask_last\") - pl.col(\"bid_last\")) / PIP\n",
    "    )\n",
    "    top = (\n",
    "        df.select([\"ts\", \"bid_last\", \"ask_last\", \"ticks\", \"spread_pips\"])\n",
    "          .sort(\"spread_pips\", descending=True)\n",
    "          .head(10)\n",
    "          .with_columns(pl.lit(f.name).alias(\"file\"))\n",
    "    )\n",
    "    rows.append(top)\n",
    "\n",
    "out = pl.concat(rows).sort(\"spread_pips\", descending=True)\n",
    "\n",
    "print(\"=== TOP 50 SPREAD BARS (2025) ===\")\n",
    "print(out.head(50))\n",
    "\n",
    "print(\"\\n=== PEOR CASO ===\")\n",
    "print(out.head(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
